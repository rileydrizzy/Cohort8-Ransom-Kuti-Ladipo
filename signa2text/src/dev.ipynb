{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:552: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from trainer import LitModule, wandb_logger, profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_w(model):\n",
    "    # Access the model's state dictionary\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    # Print the keys and shapes of the model's parameters\n",
    "    for key, value in state_dict.items():\n",
    "        print(f\"Parameter: {key}, Size: {value.size()}\")\n",
    "\n",
    "    # Alternatively, you can directly print the state_dict\n",
    "    print(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class TESTAUTOENCODER(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Input shape: torch.Size([64, 784])\n",
      "Target shape: torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return sample.view(-1), sample.view(-1)  # Reshape to match the input and output size\n",
    "\n",
    "# Generate sample data\n",
    "num_samples = 1000\n",
    "input_dim = 28 * 28  # Adjusted to match the input size of the Encoder\n",
    "\n",
    "# Create synthetic data (random numbers)\n",
    "data = torch.randn(num_samples, input_dim)\n",
    "\n",
    "# Create an instance of the CustomDataset\n",
    "dataset = CustomDataset(data)\n",
    "\n",
    "# Define batch size for DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test the DataLoader by iterating through a few batches\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Target shape:\", targets.shape)\n",
    "    break  # Stop after the first batch for demonstration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: encoder.l1.0.weight, Size: torch.Size([64, 784])\n",
      "Parameter: encoder.l1.0.bias, Size: torch.Size([64])\n",
      "Parameter: encoder.l1.2.weight, Size: torch.Size([3, 64])\n",
      "Parameter: encoder.l1.2.bias, Size: torch.Size([3])\n",
      "Parameter: decoder.l1.0.weight, Size: torch.Size([64, 3])\n",
      "Parameter: decoder.l1.0.bias, Size: torch.Size([64])\n",
      "Parameter: decoder.l1.2.weight, Size: torch.Size([784, 64])\n",
      "Parameter: decoder.l1.2.bias, Size: torch.Size([784])\n",
      "OrderedDict([('encoder.l1.0.weight', tensor([[-0.0161,  0.0290, -0.0210,  ...,  0.0026,  0.0268,  0.0169],\n",
      "        [-0.0016, -0.0153, -0.0268,  ...,  0.0312,  0.0130, -0.0154],\n",
      "        [ 0.0150, -0.0332,  0.0200,  ...,  0.0074,  0.0344, -0.0218],\n",
      "        ...,\n",
      "        [-0.0328,  0.0232,  0.0154,  ..., -0.0357,  0.0335, -0.0088],\n",
      "        [-0.0296, -0.0015, -0.0194,  ...,  0.0030,  0.0158,  0.0228],\n",
      "        [ 0.0085,  0.0144, -0.0004,  ..., -0.0089,  0.0054,  0.0033]])), ('encoder.l1.0.bias', tensor([ 0.0029, -0.0243,  0.0221, -0.0050, -0.0082, -0.0077,  0.0009,  0.0130,\n",
      "        -0.0181, -0.0223,  0.0344,  0.0262,  0.0338, -0.0156, -0.0088, -0.0090,\n",
      "         0.0106, -0.0137,  0.0143,  0.0227,  0.0113, -0.0217, -0.0056,  0.0225,\n",
      "         0.0180, -0.0205,  0.0010, -0.0065, -0.0351,  0.0092, -0.0330,  0.0156,\n",
      "        -0.0197,  0.0212,  0.0174,  0.0170, -0.0094, -0.0077, -0.0101,  0.0202,\n",
      "         0.0037, -0.0121,  0.0235, -0.0315, -0.0264,  0.0308, -0.0248, -0.0054,\n",
      "         0.0174, -0.0151, -0.0092,  0.0321,  0.0315,  0.0175, -0.0034,  0.0158,\n",
      "         0.0095, -0.0112, -0.0218,  0.0306,  0.0200,  0.0337,  0.0213,  0.0032])), ('encoder.l1.2.weight', tensor([[ 0.0797, -0.0958,  0.0099,  0.0600,  0.0017,  0.1065, -0.0641, -0.0485,\n",
      "         -0.0385,  0.1220, -0.0865,  0.0515,  0.1212,  0.0219,  0.0136, -0.0624,\n",
      "         -0.0722, -0.0795, -0.1227, -0.0584, -0.0238, -0.0505,  0.0492,  0.1246,\n",
      "         -0.0588,  0.0361,  0.0027,  0.0761,  0.0119,  0.1129,  0.0305,  0.0077,\n",
      "         -0.0250, -0.0829, -0.1187, -0.0537,  0.0693,  0.0226,  0.0991, -0.0807,\n",
      "         -0.0639, -0.0225,  0.0439, -0.0903,  0.0274,  0.1223,  0.0729,  0.0571,\n",
      "          0.0153, -0.0350,  0.1206, -0.0878, -0.0657, -0.1245,  0.1100, -0.0445,\n",
      "         -0.0731,  0.0550, -0.1013, -0.0094,  0.1235,  0.0800, -0.0993,  0.0645],\n",
      "        [-0.1229, -0.0392,  0.1198, -0.0620,  0.0974, -0.1188,  0.0764, -0.0839,\n",
      "          0.0177,  0.0944, -0.1002, -0.0651,  0.0534,  0.1035, -0.0021,  0.1194,\n",
      "         -0.0414, -0.0465,  0.0358,  0.1025,  0.0476, -0.0221, -0.1199, -0.0360,\n",
      "         -0.0103,  0.0842,  0.0246, -0.0465,  0.1005,  0.0107, -0.0734, -0.0610,\n",
      "          0.0342,  0.1219, -0.1081,  0.0237,  0.0027,  0.0219,  0.1160, -0.0887,\n",
      "          0.0814, -0.0075, -0.0479, -0.1224,  0.0191,  0.0765,  0.0102,  0.1043,\n",
      "         -0.1163, -0.0401,  0.0229, -0.0055, -0.0115,  0.0149, -0.0598, -0.0730,\n",
      "         -0.0510, -0.1006,  0.1127, -0.0294,  0.0317, -0.0417,  0.0538,  0.0626],\n",
      "        [ 0.0158,  0.1132, -0.0764, -0.1041, -0.0065, -0.1123,  0.1031,  0.0013,\n",
      "         -0.0638,  0.0534, -0.0804, -0.0851, -0.0350, -0.0359,  0.0336,  0.1043,\n",
      "          0.0188,  0.1053,  0.0114,  0.0827, -0.0257, -0.1160, -0.0252,  0.0469,\n",
      "         -0.0007, -0.1070,  0.0085, -0.0812,  0.0854,  0.0530,  0.0782,  0.0021,\n",
      "         -0.0099, -0.0193,  0.0387,  0.0848,  0.0007, -0.1188, -0.0573,  0.0062,\n",
      "         -0.0134,  0.0308, -0.0954, -0.0710, -0.0513, -0.0727,  0.0079, -0.0655,\n",
      "         -0.0042,  0.0939, -0.0431,  0.0513,  0.0568,  0.0080,  0.0887,  0.0577,\n",
      "         -0.0119, -0.0874,  0.0295, -0.0380, -0.0075,  0.0767, -0.0398,  0.1249]])), ('encoder.l1.2.bias', tensor([ 0.0044, -0.1242,  0.0145])), ('decoder.l1.0.weight', tensor([[ 0.1946,  0.5448, -0.5477],\n",
      "        [-0.4531, -0.5597, -0.5004],\n",
      "        [-0.0912,  0.0986,  0.0100],\n",
      "        [-0.3750,  0.0016, -0.4176],\n",
      "        [-0.2479, -0.4960,  0.0382],\n",
      "        [ 0.4240, -0.3587, -0.1521],\n",
      "        [ 0.5149,  0.5564, -0.3616],\n",
      "        [ 0.4699, -0.3926,  0.1822],\n",
      "        [-0.2125, -0.3833,  0.5197],\n",
      "        [-0.3506,  0.1079,  0.2272],\n",
      "        [ 0.3986, -0.4340, -0.1727],\n",
      "        [ 0.4324, -0.2078, -0.3340],\n",
      "        [ 0.4268, -0.5310,  0.1525],\n",
      "        [-0.2919,  0.0684, -0.2842],\n",
      "        [-0.5397, -0.0622, -0.1352],\n",
      "        [ 0.4102, -0.0905, -0.1259],\n",
      "        [-0.1157,  0.2082,  0.3824],\n",
      "        [ 0.2567, -0.0530,  0.0794],\n",
      "        [ 0.3440,  0.3632,  0.0459],\n",
      "        [ 0.5438,  0.3557, -0.0623],\n",
      "        [ 0.1514, -0.3847,  0.1299],\n",
      "        [-0.4964,  0.5458, -0.0082],\n",
      "        [-0.2622, -0.5508,  0.2186],\n",
      "        [-0.4138,  0.0974, -0.5517],\n",
      "        [-0.4896,  0.3918,  0.5588],\n",
      "        [-0.4728, -0.3465, -0.0937],\n",
      "        [-0.4963,  0.5733, -0.4463],\n",
      "        [ 0.0336, -0.1130,  0.4494],\n",
      "        [ 0.3325, -0.3890,  0.1600],\n",
      "        [-0.1199,  0.0646, -0.2154],\n",
      "        [-0.2496,  0.0511,  0.1005],\n",
      "        [ 0.3666, -0.1419,  0.1429],\n",
      "        [-0.3864,  0.1292,  0.4217],\n",
      "        [-0.3054,  0.4700, -0.5134],\n",
      "        [-0.0853, -0.0134,  0.4648],\n",
      "        [-0.0587, -0.1024, -0.1263],\n",
      "        [-0.0634, -0.4932,  0.3910],\n",
      "        [-0.3361,  0.1234, -0.0953],\n",
      "        [ 0.3643, -0.1023,  0.3543],\n",
      "        [ 0.3935,  0.4899,  0.2321],\n",
      "        [-0.4553,  0.4506,  0.5338],\n",
      "        [-0.4766,  0.3746,  0.0970],\n",
      "        [-0.4589, -0.4277,  0.5429],\n",
      "        [ 0.1559, -0.1243, -0.4774],\n",
      "        [-0.0782,  0.4699,  0.2337],\n",
      "        [-0.1607,  0.4665, -0.0656],\n",
      "        [ 0.3692, -0.3357, -0.1945],\n",
      "        [-0.0342, -0.0016, -0.4171],\n",
      "        [-0.3797,  0.5259,  0.5670],\n",
      "        [-0.1085,  0.5726,  0.3105],\n",
      "        [ 0.3544, -0.5021, -0.3723],\n",
      "        [ 0.1099,  0.5076, -0.5576],\n",
      "        [-0.4220,  0.3191, -0.3847],\n",
      "        [-0.4081,  0.3913,  0.0641],\n",
      "        [ 0.2544,  0.1852, -0.0366],\n",
      "        [-0.4157, -0.4916, -0.5723],\n",
      "        [ 0.2723, -0.4167, -0.1948],\n",
      "        [ 0.5046,  0.5332, -0.5157],\n",
      "        [ 0.1996, -0.1512,  0.2276],\n",
      "        [ 0.2749,  0.4940,  0.1034],\n",
      "        [ 0.4075, -0.3445,  0.4206],\n",
      "        [ 0.4558,  0.3616,  0.3863],\n",
      "        [-0.3498,  0.1798,  0.2734],\n",
      "        [-0.5609, -0.4470, -0.4983]])), ('decoder.l1.0.bias', tensor([ 0.3924,  0.5550, -0.5764, -0.3192,  0.3277,  0.3166, -0.0637,  0.3956,\n",
      "         0.1453, -0.3763, -0.3823,  0.1422, -0.0018,  0.2105,  0.5157,  0.3327,\n",
      "        -0.3198, -0.0707,  0.4434,  0.4223, -0.4814,  0.3755, -0.5389, -0.3383,\n",
      "        -0.3621,  0.3627,  0.4800,  0.3350, -0.4023,  0.4487,  0.5537, -0.5547,\n",
      "         0.2592,  0.4841,  0.2493, -0.4968, -0.2912, -0.4378, -0.3533, -0.5050,\n",
      "        -0.2398,  0.0241,  0.2644, -0.2438,  0.3147, -0.3033, -0.3294, -0.0150,\n",
      "         0.2531, -0.3787,  0.4386,  0.4813, -0.5639,  0.5175,  0.5403,  0.1303,\n",
      "        -0.5340, -0.0120, -0.2559,  0.2206,  0.1401, -0.1983, -0.0911,  0.0576])), ('decoder.l1.2.weight', tensor([[ 0.0465,  0.0401,  0.0231,  ...,  0.0082, -0.0274,  0.0169],\n",
      "        [ 0.0829,  0.1212, -0.0961,  ...,  0.0644, -0.0584, -0.1234],\n",
      "        [-0.0302,  0.0363, -0.0114,  ...,  0.0775,  0.0289,  0.0492],\n",
      "        ...,\n",
      "        [ 0.0930, -0.0719, -0.0579,  ..., -0.1176, -0.1144,  0.0324],\n",
      "        [ 0.0345, -0.0235,  0.0951,  ..., -0.1200,  0.1186, -0.0362],\n",
      "        [ 0.0850, -0.0970, -0.0700,  ..., -0.1157, -0.0325, -0.1218]])), ('decoder.l1.2.bias', tensor([ 1.4372e-02, -1.4600e-02, -1.1377e-01,  1.2290e-01,  6.9330e-02,\n",
      "        -5.8998e-02,  6.5707e-03,  7.6808e-02,  1.1582e-01,  3.0748e-02,\n",
      "        -1.2176e-01, -8.8508e-03,  8.3526e-02,  7.0642e-02, -1.0981e-01,\n",
      "         7.6913e-02,  3.9352e-03,  7.0069e-02,  2.2708e-02,  1.4610e-02,\n",
      "        -1.0949e-01, -1.0598e-01,  4.0410e-02, -6.6863e-03, -1.0800e-01,\n",
      "         6.4247e-02,  9.2230e-02, -2.0071e-02,  8.7831e-02, -1.3382e-03,\n",
      "         7.6090e-02,  4.2099e-02, -4.0801e-02,  9.1317e-02,  7.9924e-02,\n",
      "        -1.2161e-01, -1.0754e-01,  4.6101e-03,  1.6162e-02, -5.2519e-02,\n",
      "        -8.4404e-02, -2.1094e-02,  1.0473e-01, -1.0418e-01, -1.0043e-01,\n",
      "         8.2733e-02, -6.0533e-02, -1.1320e-01, -7.2506e-02,  8.4876e-02,\n",
      "         9.7793e-02,  2.1387e-02, -5.5793e-02,  3.9296e-02,  1.0320e-01,\n",
      "         1.0920e-01, -1.2398e-01,  1.0600e-01,  9.2522e-02,  1.1737e-02,\n",
      "        -2.2009e-02, -7.5416e-02, -6.2405e-03, -1.1495e-01,  7.9613e-03,\n",
      "        -9.0256e-02,  4.5370e-02,  6.6507e-02,  1.2112e-01,  2.5116e-03,\n",
      "         8.7512e-02,  7.4659e-02,  8.7009e-02, -8.9380e-02,  9.1611e-02,\n",
      "         3.2716e-02, -8.9510e-03,  6.7585e-02, -8.4110e-02, -3.0241e-02,\n",
      "         6.9739e-02, -6.4181e-02,  5.0170e-02,  1.0293e-02, -2.2601e-02,\n",
      "         8.7570e-02,  1.0520e-01, -7.9063e-02, -9.3855e-02,  9.2309e-02,\n",
      "        -3.8285e-02, -4.6334e-02, -1.2119e-01, -2.2314e-02, -9.3984e-02,\n",
      "         3.4001e-02, -1.0018e-01,  2.1494e-03, -1.2695e-02,  5.5807e-02,\n",
      "         6.2284e-02, -1.8377e-02,  3.3798e-02, -7.7165e-02, -6.1396e-02,\n",
      "         2.6521e-02, -2.8792e-02,  1.0591e-01,  1.1321e-01, -4.3943e-02,\n",
      "         9.4291e-02, -6.0043e-02, -6.6670e-02,  8.8879e-02, -2.3906e-02,\n",
      "        -1.1454e-01,  5.6064e-02,  2.9953e-02, -1.2691e-02, -9.5752e-02,\n",
      "         1.0950e-01, -5.7985e-02, -7.2556e-02,  3.3546e-02,  6.0064e-02,\n",
      "         3.8089e-02,  4.4271e-02, -9.9614e-03, -9.6729e-02,  6.0942e-02,\n",
      "         1.6620e-02, -1.2636e-02, -2.7227e-02,  5.7379e-02,  3.5538e-02,\n",
      "        -6.6052e-02, -4.7914e-02, -9.3597e-02, -2.2939e-02, -3.0096e-02,\n",
      "        -9.8544e-02, -8.0525e-03,  2.9739e-02, -7.2151e-02,  7.4928e-02,\n",
      "        -2.2940e-02, -1.0855e-02, -2.8754e-02,  9.4861e-03, -7.8899e-02,\n",
      "        -1.2151e-01, -5.3835e-02,  1.2283e-01,  1.1125e-02,  8.9651e-02,\n",
      "        -2.3375e-02, -3.8092e-02, -1.5123e-02,  6.0943e-02, -9.6561e-03,\n",
      "        -9.2767e-02,  6.2271e-02,  5.1878e-02, -6.0171e-02, -4.9090e-02,\n",
      "         5.5320e-02, -9.7778e-02,  7.0644e-02,  1.0660e-02, -2.6737e-03,\n",
      "         9.0669e-02, -3.8826e-02, -3.7763e-03, -9.9200e-02,  2.0106e-02,\n",
      "        -1.4049e-03, -9.6303e-02, -9.8378e-02,  4.9282e-02,  9.0260e-02,\n",
      "        -8.0437e-02,  1.0406e-01,  1.2313e-01,  6.1000e-02,  2.6963e-02,\n",
      "        -8.0650e-02,  3.7862e-02, -7.0031e-02,  1.1224e-01,  3.1409e-02,\n",
      "        -7.0669e-03, -6.8889e-02, -8.9840e-02,  6.9585e-03,  7.9176e-02,\n",
      "        -1.1551e-01,  4.0182e-04,  6.6445e-02,  2.4095e-02,  8.2080e-02,\n",
      "         4.1199e-02, -1.1014e-01, -4.1001e-02, -1.2149e-01,  9.7252e-02,\n",
      "         8.1795e-02,  5.0876e-02,  1.0026e-01, -1.1671e-01, -2.6580e-02,\n",
      "        -1.7738e-02,  8.1113e-04, -5.9729e-03,  2.2027e-02,  9.0980e-02,\n",
      "         4.1747e-02,  5.1835e-03,  7.5894e-02,  7.4342e-02,  3.8727e-02,\n",
      "         7.8882e-02,  9.3163e-02, -4.9186e-03,  9.1423e-02,  1.0434e-02,\n",
      "        -5.9693e-04, -7.8791e-02,  2.4678e-02, -3.4595e-02, -5.6583e-02,\n",
      "        -6.0755e-02, -8.6401e-02,  8.0397e-02, -3.7200e-02, -7.8612e-03,\n",
      "        -8.4931e-02, -4.0529e-02, -2.5883e-02,  6.8797e-02,  1.1709e-01,\n",
      "         9.5830e-02, -5.7261e-02, -3.3537e-02, -7.5153e-02, -8.2443e-02,\n",
      "        -1.0013e-01, -5.5142e-02,  8.5947e-02, -6.4074e-02,  4.4803e-02,\n",
      "         6.8446e-04, -1.5860e-02, -5.5930e-02,  6.9580e-03, -7.9772e-02,\n",
      "        -1.0904e-01, -1.8290e-02,  4.7104e-02, -1.0498e-01,  7.3743e-02,\n",
      "         1.0867e-02,  1.1904e-01,  1.1966e-01, -9.0783e-02,  3.9094e-02,\n",
      "        -5.8516e-02, -1.0021e-01,  8.1855e-02,  5.9146e-03,  7.0963e-02,\n",
      "         8.3789e-02, -6.9030e-02, -6.0104e-02,  8.6547e-03, -4.4925e-02,\n",
      "         1.1096e-01, -1.0125e-01, -2.7086e-02, -4.9296e-03, -1.1282e-01,\n",
      "         1.0446e-01,  6.5299e-02,  1.1215e-01, -2.2659e-02,  5.1279e-02,\n",
      "        -1.1182e-01, -9.8295e-03,  3.9276e-02, -1.9147e-02, -1.2261e-01,\n",
      "        -1.1675e-01, -2.7107e-02,  6.0501e-02,  9.4951e-02, -1.1135e-01,\n",
      "         1.0993e-01, -9.7050e-02, -8.1753e-02,  9.6399e-02, -7.8531e-02,\n",
      "        -6.8053e-02, -4.9661e-02,  7.3285e-02,  1.8966e-02,  6.3073e-03,\n",
      "         2.6003e-03, -1.1821e-01,  1.2231e-01,  1.5104e-02,  1.8031e-02,\n",
      "        -5.4394e-02,  1.1367e-01, -5.8026e-02, -6.2700e-02, -5.3021e-02,\n",
      "        -5.2246e-02, -3.5376e-02, -1.0794e-01,  5.1341e-02,  6.2631e-02,\n",
      "        -6.7377e-02,  6.0642e-02,  6.6562e-02, -1.1086e-01,  9.0756e-02,\n",
      "        -9.2624e-02, -8.8836e-02, -5.1266e-02,  1.2425e-01,  1.0436e-01,\n",
      "        -7.9925e-02, -9.3843e-02,  5.2534e-02, -6.3721e-02, -1.1515e-01,\n",
      "        -4.2151e-02, -1.0201e-01, -2.5830e-02,  5.4003e-02,  2.1444e-02,\n",
      "        -1.2168e-01, -1.2303e-01, -3.9467e-02,  1.1009e-01, -6.2606e-02,\n",
      "         3.1798e-02,  7.3776e-02,  4.8896e-02, -2.6778e-02,  1.0685e-01,\n",
      "         5.8782e-02, -1.9747e-02,  7.7528e-02, -9.6083e-02,  2.6045e-02,\n",
      "        -3.8183e-02, -6.5418e-02,  7.2929e-02, -1.7186e-02, -1.0559e-01,\n",
      "         1.0779e-01,  6.2756e-02,  2.5355e-02,  4.8983e-02,  4.6187e-02,\n",
      "        -1.0607e-01,  7.8917e-02,  1.0308e-01,  3.8391e-03, -1.1336e-01,\n",
      "        -1.0165e-01, -2.6113e-02,  1.2199e-01,  2.4155e-02, -8.0322e-02,\n",
      "         1.2040e-01, -2.3335e-02,  5.5820e-02,  3.7120e-03,  2.4759e-02,\n",
      "         7.1767e-02, -1.0880e-01, -3.7053e-02, -9.3895e-02, -1.2110e-01,\n",
      "        -2.4646e-02, -2.2628e-02, -9.3463e-02,  6.8166e-02,  1.2002e-01,\n",
      "        -8.3465e-02, -1.1000e-01, -1.1995e-01, -7.4217e-02,  5.8321e-02,\n",
      "        -1.0180e-01, -5.4690e-02,  6.1946e-02,  1.1468e-01, -1.2276e-01,\n",
      "         1.6633e-02, -6.0694e-02, -5.2883e-02,  4.4183e-02,  3.0982e-02,\n",
      "        -1.0046e-01,  3.1349e-02,  5.0453e-02,  3.3638e-02,  4.8459e-02,\n",
      "        -1.0673e-01,  3.5762e-02, -8.7735e-02,  9.8160e-02, -8.0092e-02,\n",
      "         5.7670e-02,  1.0677e-01, -1.9525e-03,  9.7802e-02, -8.5593e-02,\n",
      "        -6.3811e-02,  5.7560e-02,  3.7186e-02,  3.4765e-02, -9.2554e-02,\n",
      "        -9.2779e-02, -3.7788e-04, -1.0030e-01,  4.7228e-02,  4.2996e-03,\n",
      "        -7.1151e-02,  8.3291e-02, -5.8233e-02, -9.3772e-02, -5.6482e-02,\n",
      "        -7.9328e-02,  1.1392e-01, -4.0370e-02, -3.9080e-02,  4.9954e-02,\n",
      "        -4.2460e-02,  2.1316e-02, -1.0003e-01,  9.5903e-02, -3.4333e-02,\n",
      "        -9.7736e-02,  2.6157e-02, -6.2553e-02,  1.5467e-02,  7.6526e-02,\n",
      "        -7.4117e-02, -2.2152e-02, -8.1059e-02,  9.6679e-02, -1.0616e-01,\n",
      "         4.6699e-02, -2.9352e-02, -5.7882e-02,  9.6525e-02, -2.4457e-02,\n",
      "         4.9569e-02, -1.0448e-01,  8.8795e-02, -6.4076e-04,  1.9487e-02,\n",
      "        -2.1629e-03,  4.9231e-02,  7.8598e-02, -7.7301e-02,  7.6904e-02,\n",
      "         6.6451e-02, -8.6514e-02,  4.7094e-02, -6.2586e-03, -7.2690e-02,\n",
      "         9.9393e-03, -3.5884e-02, -7.9815e-02,  9.1382e-02, -4.8191e-02,\n",
      "        -1.0313e-01, -9.4362e-02, -8.9497e-02, -1.1770e-01,  5.4329e-02,\n",
      "        -8.3841e-02, -1.3593e-03,  7.7091e-02, -6.0212e-02, -7.1923e-02,\n",
      "        -3.1523e-02,  1.0300e-01, -4.8265e-03, -1.3605e-02,  2.6253e-02,\n",
      "        -7.5009e-02, -3.1037e-02,  5.6160e-02,  6.0196e-02,  1.1171e-01,\n",
      "        -1.1072e-01,  1.0793e-01,  2.2746e-02,  9.8136e-02, -4.9944e-03,\n",
      "        -2.5851e-03, -1.4863e-02,  3.8655e-02,  7.7263e-04,  1.1672e-01,\n",
      "         1.2456e-01, -9.1508e-02, -1.0644e-01, -9.2363e-02, -4.1858e-02,\n",
      "        -8.0036e-02, -1.8299e-02, -1.1519e-01, -2.7473e-02, -1.0083e-01,\n",
      "         8.4743e-02, -7.7935e-03,  6.1344e-02,  4.2780e-02, -7.8962e-02,\n",
      "        -1.9076e-02,  1.8787e-02, -9.4279e-02,  1.1866e-01,  3.0415e-02,\n",
      "         4.9971e-02, -1.2287e-01,  1.0521e-02,  7.5959e-02,  2.6639e-02,\n",
      "        -1.2930e-02,  1.1914e-01,  7.0699e-02, -9.9608e-02,  1.8484e-02,\n",
      "        -1.3166e-02, -1.1520e-02,  3.5404e-02, -1.1495e-02,  1.1789e-01,\n",
      "        -6.1494e-02, -7.3322e-02,  5.3817e-02, -1.0384e-01, -6.4155e-02,\n",
      "        -1.0445e-01,  1.2291e-01, -5.8376e-02, -6.3809e-02, -7.6616e-02,\n",
      "         5.0373e-02, -9.3513e-02,  1.0090e-01, -1.1272e-01, -2.1314e-02,\n",
      "         5.3838e-02, -2.1733e-02,  7.1247e-02, -1.2432e-02, -9.7302e-03,\n",
      "        -4.2960e-02, -1.0078e-01, -7.6138e-02,  5.8997e-02, -7.9338e-02,\n",
      "        -9.9619e-02, -5.5326e-02, -1.4279e-02,  1.3631e-02,  6.9141e-02,\n",
      "        -9.0536e-02, -4.2934e-02,  7.6604e-02,  3.4160e-02, -8.2408e-02,\n",
      "        -2.4876e-02,  1.0182e-02,  8.5373e-03,  7.2864e-02, -6.1003e-02,\n",
      "         1.1706e-01,  8.1988e-02,  1.1969e-02,  3.6497e-02,  4.4288e-04,\n",
      "         8.5908e-02, -1.9977e-03, -7.9481e-02,  1.0641e-01, -9.2023e-02,\n",
      "         3.3674e-02,  5.0291e-04, -4.4374e-03, -4.6683e-02,  4.2323e-02,\n",
      "        -9.7228e-02,  1.0310e-01,  1.1294e-01, -2.3064e-02, -9.4661e-02,\n",
      "        -1.1938e-01, -2.7283e-02, -7.8253e-02, -5.0774e-02, -1.1842e-01,\n",
      "        -2.5792e-02, -1.2862e-03, -7.5456e-02, -4.9305e-02,  9.3443e-02,\n",
      "         2.2346e-02, -2.3583e-02, -4.7395e-02,  5.6247e-02, -8.4862e-03,\n",
      "         2.5871e-02, -1.1900e-01, -6.6600e-02,  9.8455e-02,  9.6956e-02,\n",
      "         1.2230e-01,  6.0214e-02, -7.1027e-02,  5.8924e-02,  7.8913e-03,\n",
      "         5.6636e-02,  3.5537e-02,  3.7864e-02,  6.6084e-02,  6.8382e-03,\n",
      "        -7.2687e-02, -7.6546e-02, -4.4388e-02, -3.7135e-02, -1.1852e-01,\n",
      "        -3.8720e-02,  2.5432e-02,  1.1149e-04, -1.1155e-01, -7.1943e-02,\n",
      "         4.9687e-02,  1.1744e-01, -2.0265e-02,  1.1799e-02,  1.2332e-01,\n",
      "         4.4423e-02, -1.0187e-01, -7.4852e-02, -7.9031e-03, -6.8050e-03,\n",
      "         7.3423e-02,  9.5772e-02,  1.1727e-01,  5.9597e-02, -1.1710e-01,\n",
      "         7.1536e-02,  1.1756e-01,  3.8345e-02,  4.8359e-02,  4.3071e-02,\n",
      "         1.0686e-01, -6.6669e-02, -7.4686e-02, -4.7133e-02, -2.2593e-02,\n",
      "         2.9394e-02, -3.4635e-02, -2.2354e-02,  7.7806e-02,  1.2047e-01,\n",
      "        -5.6874e-02, -7.3498e-02, -5.3431e-02,  9.3585e-02, -5.1219e-02,\n",
      "         1.0976e-01, -9.3627e-02, -5.3812e-02,  1.1300e-01,  4.7074e-02,\n",
      "        -9.7930e-02, -5.7770e-02,  1.1041e-02,  8.9856e-02,  1.1482e-01,\n",
      "        -2.9930e-02,  8.2576e-02,  1.2270e-01,  7.9538e-03,  1.8046e-02,\n",
      "         1.0287e-01, -1.0555e-01, -6.9573e-02,  3.9952e-02,  1.8373e-02,\n",
      "         9.3662e-02,  8.5799e-02,  1.2417e-01, -7.8419e-02, -3.4493e-02,\n",
      "        -6.6691e-02,  7.6119e-03,  7.7165e-02,  6.9167e-02, -9.1499e-02,\n",
      "         4.5646e-02, -7.2709e-03, -2.4126e-02,  3.1146e-02, -5.3018e-03,\n",
      "         2.3287e-02,  6.4497e-02, -7.6322e-02, -7.5927e-02, -7.7227e-02,\n",
      "        -1.8314e-02,  6.7873e-03, -9.6870e-02,  1.1539e-01, -9.4570e-02,\n",
      "        -8.7918e-02,  3.1682e-02, -2.4789e-02,  9.9458e-02, -6.4607e-02,\n",
      "        -8.7402e-02,  1.1708e-01, -6.2988e-02, -6.2958e-03, -4.1805e-02,\n",
      "         2.3832e-02, -1.0176e-01, -5.2356e-02, -5.2288e-02,  8.5669e-02,\n",
      "         6.8505e-02, -6.3248e-02, -1.6879e-02, -2.7382e-02, -2.1840e-02,\n",
      "         2.3431e-02, -7.9552e-02, -1.0208e-01,  2.8098e-02, -1.1157e-01,\n",
      "        -1.7213e-02, -8.4040e-02, -1.3586e-03, -1.1422e-01, -2.0420e-02,\n",
      "        -3.9404e-03, -2.7651e-02,  1.1988e-01, -6.9561e-03, -2.9447e-02,\n",
      "        -9.9871e-02, -1.2078e-01,  3.3731e-02,  2.8366e-02,  6.9814e-02,\n",
      "        -6.6926e-02, -4.5807e-02, -4.9858e-02,  8.2351e-02,  3.9172e-02,\n",
      "        -3.9391e-02,  1.1587e-01,  1.1197e-01,  6.9504e-02, -3.5825e-02,\n",
      "        -7.0754e-02,  7.0469e-02, -1.1818e-01,  7.9868e-02,  6.6377e-03,\n",
      "        -7.3947e-03, -7.9162e-03,  1.7170e-02, -4.2426e-02]))])\n"
     ]
    }
   ],
   "source": [
    "test_model = TESTAUTOENCODER()\n",
    "check_model_w(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrileydrizzy\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240218_152929-787okxtp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/rileydrizzy/NSL_2_AUDIO/runs/787okxtp' target=\"_blank\">festive-envelope-13</a></strong> to <a href='https://wandb.ai/rileydrizzy/NSL_2_AUDIO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rileydrizzy/NSL_2_AUDIO' target=\"_blank\">https://wandb.ai/rileydrizzy/NSL_2_AUDIO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rileydrizzy/NSL_2_AUDIO/runs/787okxtp' target=\"_blank\">https://wandb.ai/rileydrizzy/NSL_2_AUDIO/runs/787okxtp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "MODEL_ = LitModule(model=test_model, loss_criterion=F.mse_loss, metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: model.encoder.l1.0.weight, Size: torch.Size([64, 784])\n",
      "Parameter: model.encoder.l1.0.bias, Size: torch.Size([64])\n",
      "Parameter: model.encoder.l1.2.weight, Size: torch.Size([3, 64])\n",
      "Parameter: model.encoder.l1.2.bias, Size: torch.Size([3])\n",
      "Parameter: model.decoder.l1.0.weight, Size: torch.Size([64, 3])\n",
      "Parameter: model.decoder.l1.0.bias, Size: torch.Size([64])\n",
      "Parameter: model.decoder.l1.2.weight, Size: torch.Size([784, 64])\n",
      "Parameter: model.decoder.l1.2.bias, Size: torch.Size([784])\n",
      "OrderedDict([('model.encoder.l1.0.weight', tensor([[-0.0161,  0.0290, -0.0210,  ...,  0.0026,  0.0268,  0.0169],\n",
      "        [-0.0016, -0.0153, -0.0268,  ...,  0.0312,  0.0130, -0.0154],\n",
      "        [ 0.0150, -0.0332,  0.0200,  ...,  0.0074,  0.0344, -0.0218],\n",
      "        ...,\n",
      "        [-0.0328,  0.0232,  0.0154,  ..., -0.0357,  0.0335, -0.0088],\n",
      "        [-0.0296, -0.0015, -0.0194,  ...,  0.0030,  0.0158,  0.0228],\n",
      "        [ 0.0085,  0.0144, -0.0004,  ..., -0.0089,  0.0054,  0.0033]])), ('model.encoder.l1.0.bias', tensor([ 0.0029, -0.0243,  0.0221, -0.0050, -0.0082, -0.0077,  0.0009,  0.0130,\n",
      "        -0.0181, -0.0223,  0.0344,  0.0262,  0.0338, -0.0156, -0.0088, -0.0090,\n",
      "         0.0106, -0.0137,  0.0143,  0.0227,  0.0113, -0.0217, -0.0056,  0.0225,\n",
      "         0.0180, -0.0205,  0.0010, -0.0065, -0.0351,  0.0092, -0.0330,  0.0156,\n",
      "        -0.0197,  0.0212,  0.0174,  0.0170, -0.0094, -0.0077, -0.0101,  0.0202,\n",
      "         0.0037, -0.0121,  0.0235, -0.0315, -0.0264,  0.0308, -0.0248, -0.0054,\n",
      "         0.0174, -0.0151, -0.0092,  0.0321,  0.0315,  0.0175, -0.0034,  0.0158,\n",
      "         0.0095, -0.0112, -0.0218,  0.0306,  0.0200,  0.0337,  0.0213,  0.0032])), ('model.encoder.l1.2.weight', tensor([[ 0.0797, -0.0958,  0.0099,  0.0600,  0.0017,  0.1065, -0.0641, -0.0485,\n",
      "         -0.0385,  0.1220, -0.0865,  0.0515,  0.1212,  0.0219,  0.0136, -0.0624,\n",
      "         -0.0722, -0.0795, -0.1227, -0.0584, -0.0238, -0.0505,  0.0492,  0.1246,\n",
      "         -0.0588,  0.0361,  0.0027,  0.0761,  0.0119,  0.1129,  0.0305,  0.0077,\n",
      "         -0.0250, -0.0829, -0.1187, -0.0537,  0.0693,  0.0226,  0.0991, -0.0807,\n",
      "         -0.0639, -0.0225,  0.0439, -0.0903,  0.0274,  0.1223,  0.0729,  0.0571,\n",
      "          0.0153, -0.0350,  0.1206, -0.0878, -0.0657, -0.1245,  0.1100, -0.0445,\n",
      "         -0.0731,  0.0550, -0.1013, -0.0094,  0.1235,  0.0800, -0.0993,  0.0645],\n",
      "        [-0.1229, -0.0392,  0.1198, -0.0620,  0.0974, -0.1188,  0.0764, -0.0839,\n",
      "          0.0177,  0.0944, -0.1002, -0.0651,  0.0534,  0.1035, -0.0021,  0.1194,\n",
      "         -0.0414, -0.0465,  0.0358,  0.1025,  0.0476, -0.0221, -0.1199, -0.0360,\n",
      "         -0.0103,  0.0842,  0.0246, -0.0465,  0.1005,  0.0107, -0.0734, -0.0610,\n",
      "          0.0342,  0.1219, -0.1081,  0.0237,  0.0027,  0.0219,  0.1160, -0.0887,\n",
      "          0.0814, -0.0075, -0.0479, -0.1224,  0.0191,  0.0765,  0.0102,  0.1043,\n",
      "         -0.1163, -0.0401,  0.0229, -0.0055, -0.0115,  0.0149, -0.0598, -0.0730,\n",
      "         -0.0510, -0.1006,  0.1127, -0.0294,  0.0317, -0.0417,  0.0538,  0.0626],\n",
      "        [ 0.0158,  0.1132, -0.0764, -0.1041, -0.0065, -0.1123,  0.1031,  0.0013,\n",
      "         -0.0638,  0.0534, -0.0804, -0.0851, -0.0350, -0.0359,  0.0336,  0.1043,\n",
      "          0.0188,  0.1053,  0.0114,  0.0827, -0.0257, -0.1160, -0.0252,  0.0469,\n",
      "         -0.0007, -0.1070,  0.0085, -0.0812,  0.0854,  0.0530,  0.0782,  0.0021,\n",
      "         -0.0099, -0.0193,  0.0387,  0.0848,  0.0007, -0.1188, -0.0573,  0.0062,\n",
      "         -0.0134,  0.0308, -0.0954, -0.0710, -0.0513, -0.0727,  0.0079, -0.0655,\n",
      "         -0.0042,  0.0939, -0.0431,  0.0513,  0.0568,  0.0080,  0.0887,  0.0577,\n",
      "         -0.0119, -0.0874,  0.0295, -0.0380, -0.0075,  0.0767, -0.0398,  0.1249]])), ('model.encoder.l1.2.bias', tensor([ 0.0044, -0.1242,  0.0145])), ('model.decoder.l1.0.weight', tensor([[ 0.1946,  0.5448, -0.5477],\n",
      "        [-0.4531, -0.5597, -0.5004],\n",
      "        [-0.0912,  0.0986,  0.0100],\n",
      "        [-0.3750,  0.0016, -0.4176],\n",
      "        [-0.2479, -0.4960,  0.0382],\n",
      "        [ 0.4240, -0.3587, -0.1521],\n",
      "        [ 0.5149,  0.5564, -0.3616],\n",
      "        [ 0.4699, -0.3926,  0.1822],\n",
      "        [-0.2125, -0.3833,  0.5197],\n",
      "        [-0.3506,  0.1079,  0.2272],\n",
      "        [ 0.3986, -0.4340, -0.1727],\n",
      "        [ 0.4324, -0.2078, -0.3340],\n",
      "        [ 0.4268, -0.5310,  0.1525],\n",
      "        [-0.2919,  0.0684, -0.2842],\n",
      "        [-0.5397, -0.0622, -0.1352],\n",
      "        [ 0.4102, -0.0905, -0.1259],\n",
      "        [-0.1157,  0.2082,  0.3824],\n",
      "        [ 0.2567, -0.0530,  0.0794],\n",
      "        [ 0.3440,  0.3632,  0.0459],\n",
      "        [ 0.5438,  0.3557, -0.0623],\n",
      "        [ 0.1514, -0.3847,  0.1299],\n",
      "        [-0.4964,  0.5458, -0.0082],\n",
      "        [-0.2622, -0.5508,  0.2186],\n",
      "        [-0.4138,  0.0974, -0.5517],\n",
      "        [-0.4896,  0.3918,  0.5588],\n",
      "        [-0.4728, -0.3465, -0.0937],\n",
      "        [-0.4963,  0.5733, -0.4463],\n",
      "        [ 0.0336, -0.1130,  0.4494],\n",
      "        [ 0.3325, -0.3890,  0.1600],\n",
      "        [-0.1199,  0.0646, -0.2154],\n",
      "        [-0.2496,  0.0511,  0.1005],\n",
      "        [ 0.3666, -0.1419,  0.1429],\n",
      "        [-0.3864,  0.1292,  0.4217],\n",
      "        [-0.3054,  0.4700, -0.5134],\n",
      "        [-0.0853, -0.0134,  0.4648],\n",
      "        [-0.0587, -0.1024, -0.1263],\n",
      "        [-0.0634, -0.4932,  0.3910],\n",
      "        [-0.3361,  0.1234, -0.0953],\n",
      "        [ 0.3643, -0.1023,  0.3543],\n",
      "        [ 0.3935,  0.4899,  0.2321],\n",
      "        [-0.4553,  0.4506,  0.5338],\n",
      "        [-0.4766,  0.3746,  0.0970],\n",
      "        [-0.4589, -0.4277,  0.5429],\n",
      "        [ 0.1559, -0.1243, -0.4774],\n",
      "        [-0.0782,  0.4699,  0.2337],\n",
      "        [-0.1607,  0.4665, -0.0656],\n",
      "        [ 0.3692, -0.3357, -0.1945],\n",
      "        [-0.0342, -0.0016, -0.4171],\n",
      "        [-0.3797,  0.5259,  0.5670],\n",
      "        [-0.1085,  0.5726,  0.3105],\n",
      "        [ 0.3544, -0.5021, -0.3723],\n",
      "        [ 0.1099,  0.5076, -0.5576],\n",
      "        [-0.4220,  0.3191, -0.3847],\n",
      "        [-0.4081,  0.3913,  0.0641],\n",
      "        [ 0.2544,  0.1852, -0.0366],\n",
      "        [-0.4157, -0.4916, -0.5723],\n",
      "        [ 0.2723, -0.4167, -0.1948],\n",
      "        [ 0.5046,  0.5332, -0.5157],\n",
      "        [ 0.1996, -0.1512,  0.2276],\n",
      "        [ 0.2749,  0.4940,  0.1034],\n",
      "        [ 0.4075, -0.3445,  0.4206],\n",
      "        [ 0.4558,  0.3616,  0.3863],\n",
      "        [-0.3498,  0.1798,  0.2734],\n",
      "        [-0.5609, -0.4470, -0.4983]])), ('model.decoder.l1.0.bias', tensor([ 0.3924,  0.5550, -0.5764, -0.3192,  0.3277,  0.3166, -0.0637,  0.3956,\n",
      "         0.1453, -0.3763, -0.3823,  0.1422, -0.0018,  0.2105,  0.5157,  0.3327,\n",
      "        -0.3198, -0.0707,  0.4434,  0.4223, -0.4814,  0.3755, -0.5389, -0.3383,\n",
      "        -0.3621,  0.3627,  0.4800,  0.3350, -0.4023,  0.4487,  0.5537, -0.5547,\n",
      "         0.2592,  0.4841,  0.2493, -0.4968, -0.2912, -0.4378, -0.3533, -0.5050,\n",
      "        -0.2398,  0.0241,  0.2644, -0.2438,  0.3147, -0.3033, -0.3294, -0.0150,\n",
      "         0.2531, -0.3787,  0.4386,  0.4813, -0.5639,  0.5175,  0.5403,  0.1303,\n",
      "        -0.5340, -0.0120, -0.2559,  0.2206,  0.1401, -0.1983, -0.0911,  0.0576])), ('model.decoder.l1.2.weight', tensor([[ 0.0465,  0.0401,  0.0231,  ...,  0.0082, -0.0274,  0.0169],\n",
      "        [ 0.0829,  0.1212, -0.0961,  ...,  0.0644, -0.0584, -0.1234],\n",
      "        [-0.0302,  0.0363, -0.0114,  ...,  0.0775,  0.0289,  0.0492],\n",
      "        ...,\n",
      "        [ 0.0930, -0.0719, -0.0579,  ..., -0.1176, -0.1144,  0.0324],\n",
      "        [ 0.0345, -0.0235,  0.0951,  ..., -0.1200,  0.1186, -0.0362],\n",
      "        [ 0.0850, -0.0970, -0.0700,  ..., -0.1157, -0.0325, -0.1218]])), ('model.decoder.l1.2.bias', tensor([ 1.4372e-02, -1.4600e-02, -1.1377e-01,  1.2290e-01,  6.9330e-02,\n",
      "        -5.8998e-02,  6.5707e-03,  7.6808e-02,  1.1582e-01,  3.0748e-02,\n",
      "        -1.2176e-01, -8.8508e-03,  8.3526e-02,  7.0642e-02, -1.0981e-01,\n",
      "         7.6913e-02,  3.9352e-03,  7.0069e-02,  2.2708e-02,  1.4610e-02,\n",
      "        -1.0949e-01, -1.0598e-01,  4.0410e-02, -6.6863e-03, -1.0800e-01,\n",
      "         6.4247e-02,  9.2230e-02, -2.0071e-02,  8.7831e-02, -1.3382e-03,\n",
      "         7.6090e-02,  4.2099e-02, -4.0801e-02,  9.1317e-02,  7.9924e-02,\n",
      "        -1.2161e-01, -1.0754e-01,  4.6101e-03,  1.6162e-02, -5.2519e-02,\n",
      "        -8.4404e-02, -2.1094e-02,  1.0473e-01, -1.0418e-01, -1.0043e-01,\n",
      "         8.2733e-02, -6.0533e-02, -1.1320e-01, -7.2506e-02,  8.4876e-02,\n",
      "         9.7793e-02,  2.1387e-02, -5.5793e-02,  3.9296e-02,  1.0320e-01,\n",
      "         1.0920e-01, -1.2398e-01,  1.0600e-01,  9.2522e-02,  1.1737e-02,\n",
      "        -2.2009e-02, -7.5416e-02, -6.2405e-03, -1.1495e-01,  7.9613e-03,\n",
      "        -9.0256e-02,  4.5370e-02,  6.6507e-02,  1.2112e-01,  2.5116e-03,\n",
      "         8.7512e-02,  7.4659e-02,  8.7009e-02, -8.9380e-02,  9.1611e-02,\n",
      "         3.2716e-02, -8.9510e-03,  6.7585e-02, -8.4110e-02, -3.0241e-02,\n",
      "         6.9739e-02, -6.4181e-02,  5.0170e-02,  1.0293e-02, -2.2601e-02,\n",
      "         8.7570e-02,  1.0520e-01, -7.9063e-02, -9.3855e-02,  9.2309e-02,\n",
      "        -3.8285e-02, -4.6334e-02, -1.2119e-01, -2.2314e-02, -9.3984e-02,\n",
      "         3.4001e-02, -1.0018e-01,  2.1494e-03, -1.2695e-02,  5.5807e-02,\n",
      "         6.2284e-02, -1.8377e-02,  3.3798e-02, -7.7165e-02, -6.1396e-02,\n",
      "         2.6521e-02, -2.8792e-02,  1.0591e-01,  1.1321e-01, -4.3943e-02,\n",
      "         9.4291e-02, -6.0043e-02, -6.6670e-02,  8.8879e-02, -2.3906e-02,\n",
      "        -1.1454e-01,  5.6064e-02,  2.9953e-02, -1.2691e-02, -9.5752e-02,\n",
      "         1.0950e-01, -5.7985e-02, -7.2556e-02,  3.3546e-02,  6.0064e-02,\n",
      "         3.8089e-02,  4.4271e-02, -9.9614e-03, -9.6729e-02,  6.0942e-02,\n",
      "         1.6620e-02, -1.2636e-02, -2.7227e-02,  5.7379e-02,  3.5538e-02,\n",
      "        -6.6052e-02, -4.7914e-02, -9.3597e-02, -2.2939e-02, -3.0096e-02,\n",
      "        -9.8544e-02, -8.0525e-03,  2.9739e-02, -7.2151e-02,  7.4928e-02,\n",
      "        -2.2940e-02, -1.0855e-02, -2.8754e-02,  9.4861e-03, -7.8899e-02,\n",
      "        -1.2151e-01, -5.3835e-02,  1.2283e-01,  1.1125e-02,  8.9651e-02,\n",
      "        -2.3375e-02, -3.8092e-02, -1.5123e-02,  6.0943e-02, -9.6561e-03,\n",
      "        -9.2767e-02,  6.2271e-02,  5.1878e-02, -6.0171e-02, -4.9090e-02,\n",
      "         5.5320e-02, -9.7778e-02,  7.0644e-02,  1.0660e-02, -2.6737e-03,\n",
      "         9.0669e-02, -3.8826e-02, -3.7763e-03, -9.9200e-02,  2.0106e-02,\n",
      "        -1.4049e-03, -9.6303e-02, -9.8378e-02,  4.9282e-02,  9.0260e-02,\n",
      "        -8.0437e-02,  1.0406e-01,  1.2313e-01,  6.1000e-02,  2.6963e-02,\n",
      "        -8.0650e-02,  3.7862e-02, -7.0031e-02,  1.1224e-01,  3.1409e-02,\n",
      "        -7.0669e-03, -6.8889e-02, -8.9840e-02,  6.9585e-03,  7.9176e-02,\n",
      "        -1.1551e-01,  4.0182e-04,  6.6445e-02,  2.4095e-02,  8.2080e-02,\n",
      "         4.1199e-02, -1.1014e-01, -4.1001e-02, -1.2149e-01,  9.7252e-02,\n",
      "         8.1795e-02,  5.0876e-02,  1.0026e-01, -1.1671e-01, -2.6580e-02,\n",
      "        -1.7738e-02,  8.1113e-04, -5.9729e-03,  2.2027e-02,  9.0980e-02,\n",
      "         4.1747e-02,  5.1835e-03,  7.5894e-02,  7.4342e-02,  3.8727e-02,\n",
      "         7.8882e-02,  9.3163e-02, -4.9186e-03,  9.1423e-02,  1.0434e-02,\n",
      "        -5.9693e-04, -7.8791e-02,  2.4678e-02, -3.4595e-02, -5.6583e-02,\n",
      "        -6.0755e-02, -8.6401e-02,  8.0397e-02, -3.7200e-02, -7.8612e-03,\n",
      "        -8.4931e-02, -4.0529e-02, -2.5883e-02,  6.8797e-02,  1.1709e-01,\n",
      "         9.5830e-02, -5.7261e-02, -3.3537e-02, -7.5153e-02, -8.2443e-02,\n",
      "        -1.0013e-01, -5.5142e-02,  8.5947e-02, -6.4074e-02,  4.4803e-02,\n",
      "         6.8446e-04, -1.5860e-02, -5.5930e-02,  6.9580e-03, -7.9772e-02,\n",
      "        -1.0904e-01, -1.8290e-02,  4.7104e-02, -1.0498e-01,  7.3743e-02,\n",
      "         1.0867e-02,  1.1904e-01,  1.1966e-01, -9.0783e-02,  3.9094e-02,\n",
      "        -5.8516e-02, -1.0021e-01,  8.1855e-02,  5.9146e-03,  7.0963e-02,\n",
      "         8.3789e-02, -6.9030e-02, -6.0104e-02,  8.6547e-03, -4.4925e-02,\n",
      "         1.1096e-01, -1.0125e-01, -2.7086e-02, -4.9296e-03, -1.1282e-01,\n",
      "         1.0446e-01,  6.5299e-02,  1.1215e-01, -2.2659e-02,  5.1279e-02,\n",
      "        -1.1182e-01, -9.8295e-03,  3.9276e-02, -1.9147e-02, -1.2261e-01,\n",
      "        -1.1675e-01, -2.7107e-02,  6.0501e-02,  9.4951e-02, -1.1135e-01,\n",
      "         1.0993e-01, -9.7050e-02, -8.1753e-02,  9.6399e-02, -7.8531e-02,\n",
      "        -6.8053e-02, -4.9661e-02,  7.3285e-02,  1.8966e-02,  6.3073e-03,\n",
      "         2.6003e-03, -1.1821e-01,  1.2231e-01,  1.5104e-02,  1.8031e-02,\n",
      "        -5.4394e-02,  1.1367e-01, -5.8026e-02, -6.2700e-02, -5.3021e-02,\n",
      "        -5.2246e-02, -3.5376e-02, -1.0794e-01,  5.1341e-02,  6.2631e-02,\n",
      "        -6.7377e-02,  6.0642e-02,  6.6562e-02, -1.1086e-01,  9.0756e-02,\n",
      "        -9.2624e-02, -8.8836e-02, -5.1266e-02,  1.2425e-01,  1.0436e-01,\n",
      "        -7.9925e-02, -9.3843e-02,  5.2534e-02, -6.3721e-02, -1.1515e-01,\n",
      "        -4.2151e-02, -1.0201e-01, -2.5830e-02,  5.4003e-02,  2.1444e-02,\n",
      "        -1.2168e-01, -1.2303e-01, -3.9467e-02,  1.1009e-01, -6.2606e-02,\n",
      "         3.1798e-02,  7.3776e-02,  4.8896e-02, -2.6778e-02,  1.0685e-01,\n",
      "         5.8782e-02, -1.9747e-02,  7.7528e-02, -9.6083e-02,  2.6045e-02,\n",
      "        -3.8183e-02, -6.5418e-02,  7.2929e-02, -1.7186e-02, -1.0559e-01,\n",
      "         1.0779e-01,  6.2756e-02,  2.5355e-02,  4.8983e-02,  4.6187e-02,\n",
      "        -1.0607e-01,  7.8917e-02,  1.0308e-01,  3.8391e-03, -1.1336e-01,\n",
      "        -1.0165e-01, -2.6113e-02,  1.2199e-01,  2.4155e-02, -8.0322e-02,\n",
      "         1.2040e-01, -2.3335e-02,  5.5820e-02,  3.7120e-03,  2.4759e-02,\n",
      "         7.1767e-02, -1.0880e-01, -3.7053e-02, -9.3895e-02, -1.2110e-01,\n",
      "        -2.4646e-02, -2.2628e-02, -9.3463e-02,  6.8166e-02,  1.2002e-01,\n",
      "        -8.3465e-02, -1.1000e-01, -1.1995e-01, -7.4217e-02,  5.8321e-02,\n",
      "        -1.0180e-01, -5.4690e-02,  6.1946e-02,  1.1468e-01, -1.2276e-01,\n",
      "         1.6633e-02, -6.0694e-02, -5.2883e-02,  4.4183e-02,  3.0982e-02,\n",
      "        -1.0046e-01,  3.1349e-02,  5.0453e-02,  3.3638e-02,  4.8459e-02,\n",
      "        -1.0673e-01,  3.5762e-02, -8.7735e-02,  9.8160e-02, -8.0092e-02,\n",
      "         5.7670e-02,  1.0677e-01, -1.9525e-03,  9.7802e-02, -8.5593e-02,\n",
      "        -6.3811e-02,  5.7560e-02,  3.7186e-02,  3.4765e-02, -9.2554e-02,\n",
      "        -9.2779e-02, -3.7788e-04, -1.0030e-01,  4.7228e-02,  4.2996e-03,\n",
      "        -7.1151e-02,  8.3291e-02, -5.8233e-02, -9.3772e-02, -5.6482e-02,\n",
      "        -7.9328e-02,  1.1392e-01, -4.0370e-02, -3.9080e-02,  4.9954e-02,\n",
      "        -4.2460e-02,  2.1316e-02, -1.0003e-01,  9.5903e-02, -3.4333e-02,\n",
      "        -9.7736e-02,  2.6157e-02, -6.2553e-02,  1.5467e-02,  7.6526e-02,\n",
      "        -7.4117e-02, -2.2152e-02, -8.1059e-02,  9.6679e-02, -1.0616e-01,\n",
      "         4.6699e-02, -2.9352e-02, -5.7882e-02,  9.6525e-02, -2.4457e-02,\n",
      "         4.9569e-02, -1.0448e-01,  8.8795e-02, -6.4076e-04,  1.9487e-02,\n",
      "        -2.1629e-03,  4.9231e-02,  7.8598e-02, -7.7301e-02,  7.6904e-02,\n",
      "         6.6451e-02, -8.6514e-02,  4.7094e-02, -6.2586e-03, -7.2690e-02,\n",
      "         9.9393e-03, -3.5884e-02, -7.9815e-02,  9.1382e-02, -4.8191e-02,\n",
      "        -1.0313e-01, -9.4362e-02, -8.9497e-02, -1.1770e-01,  5.4329e-02,\n",
      "        -8.3841e-02, -1.3593e-03,  7.7091e-02, -6.0212e-02, -7.1923e-02,\n",
      "        -3.1523e-02,  1.0300e-01, -4.8265e-03, -1.3605e-02,  2.6253e-02,\n",
      "        -7.5009e-02, -3.1037e-02,  5.6160e-02,  6.0196e-02,  1.1171e-01,\n",
      "        -1.1072e-01,  1.0793e-01,  2.2746e-02,  9.8136e-02, -4.9944e-03,\n",
      "        -2.5851e-03, -1.4863e-02,  3.8655e-02,  7.7263e-04,  1.1672e-01,\n",
      "         1.2456e-01, -9.1508e-02, -1.0644e-01, -9.2363e-02, -4.1858e-02,\n",
      "        -8.0036e-02, -1.8299e-02, -1.1519e-01, -2.7473e-02, -1.0083e-01,\n",
      "         8.4743e-02, -7.7935e-03,  6.1344e-02,  4.2780e-02, -7.8962e-02,\n",
      "        -1.9076e-02,  1.8787e-02, -9.4279e-02,  1.1866e-01,  3.0415e-02,\n",
      "         4.9971e-02, -1.2287e-01,  1.0521e-02,  7.5959e-02,  2.6639e-02,\n",
      "        -1.2930e-02,  1.1914e-01,  7.0699e-02, -9.9608e-02,  1.8484e-02,\n",
      "        -1.3166e-02, -1.1520e-02,  3.5404e-02, -1.1495e-02,  1.1789e-01,\n",
      "        -6.1494e-02, -7.3322e-02,  5.3817e-02, -1.0384e-01, -6.4155e-02,\n",
      "        -1.0445e-01,  1.2291e-01, -5.8376e-02, -6.3809e-02, -7.6616e-02,\n",
      "         5.0373e-02, -9.3513e-02,  1.0090e-01, -1.1272e-01, -2.1314e-02,\n",
      "         5.3838e-02, -2.1733e-02,  7.1247e-02, -1.2432e-02, -9.7302e-03,\n",
      "        -4.2960e-02, -1.0078e-01, -7.6138e-02,  5.8997e-02, -7.9338e-02,\n",
      "        -9.9619e-02, -5.5326e-02, -1.4279e-02,  1.3631e-02,  6.9141e-02,\n",
      "        -9.0536e-02, -4.2934e-02,  7.6604e-02,  3.4160e-02, -8.2408e-02,\n",
      "        -2.4876e-02,  1.0182e-02,  8.5373e-03,  7.2864e-02, -6.1003e-02,\n",
      "         1.1706e-01,  8.1988e-02,  1.1969e-02,  3.6497e-02,  4.4288e-04,\n",
      "         8.5908e-02, -1.9977e-03, -7.9481e-02,  1.0641e-01, -9.2023e-02,\n",
      "         3.3674e-02,  5.0291e-04, -4.4374e-03, -4.6683e-02,  4.2323e-02,\n",
      "        -9.7228e-02,  1.0310e-01,  1.1294e-01, -2.3064e-02, -9.4661e-02,\n",
      "        -1.1938e-01, -2.7283e-02, -7.8253e-02, -5.0774e-02, -1.1842e-01,\n",
      "        -2.5792e-02, -1.2862e-03, -7.5456e-02, -4.9305e-02,  9.3443e-02,\n",
      "         2.2346e-02, -2.3583e-02, -4.7395e-02,  5.6247e-02, -8.4862e-03,\n",
      "         2.5871e-02, -1.1900e-01, -6.6600e-02,  9.8455e-02,  9.6956e-02,\n",
      "         1.2230e-01,  6.0214e-02, -7.1027e-02,  5.8924e-02,  7.8913e-03,\n",
      "         5.6636e-02,  3.5537e-02,  3.7864e-02,  6.6084e-02,  6.8382e-03,\n",
      "        -7.2687e-02, -7.6546e-02, -4.4388e-02, -3.7135e-02, -1.1852e-01,\n",
      "        -3.8720e-02,  2.5432e-02,  1.1149e-04, -1.1155e-01, -7.1943e-02,\n",
      "         4.9687e-02,  1.1744e-01, -2.0265e-02,  1.1799e-02,  1.2332e-01,\n",
      "         4.4423e-02, -1.0187e-01, -7.4852e-02, -7.9031e-03, -6.8050e-03,\n",
      "         7.3423e-02,  9.5772e-02,  1.1727e-01,  5.9597e-02, -1.1710e-01,\n",
      "         7.1536e-02,  1.1756e-01,  3.8345e-02,  4.8359e-02,  4.3071e-02,\n",
      "         1.0686e-01, -6.6669e-02, -7.4686e-02, -4.7133e-02, -2.2593e-02,\n",
      "         2.9394e-02, -3.4635e-02, -2.2354e-02,  7.7806e-02,  1.2047e-01,\n",
      "        -5.6874e-02, -7.3498e-02, -5.3431e-02,  9.3585e-02, -5.1219e-02,\n",
      "         1.0976e-01, -9.3627e-02, -5.3812e-02,  1.1300e-01,  4.7074e-02,\n",
      "        -9.7930e-02, -5.7770e-02,  1.1041e-02,  8.9856e-02,  1.1482e-01,\n",
      "        -2.9930e-02,  8.2576e-02,  1.2270e-01,  7.9538e-03,  1.8046e-02,\n",
      "         1.0287e-01, -1.0555e-01, -6.9573e-02,  3.9952e-02,  1.8373e-02,\n",
      "         9.3662e-02,  8.5799e-02,  1.2417e-01, -7.8419e-02, -3.4493e-02,\n",
      "        -6.6691e-02,  7.6119e-03,  7.7165e-02,  6.9167e-02, -9.1499e-02,\n",
      "         4.5646e-02, -7.2709e-03, -2.4126e-02,  3.1146e-02, -5.3018e-03,\n",
      "         2.3287e-02,  6.4497e-02, -7.6322e-02, -7.5927e-02, -7.7227e-02,\n",
      "        -1.8314e-02,  6.7873e-03, -9.6870e-02,  1.1539e-01, -9.4570e-02,\n",
      "        -8.7918e-02,  3.1682e-02, -2.4789e-02,  9.9458e-02, -6.4607e-02,\n",
      "        -8.7402e-02,  1.1708e-01, -6.2988e-02, -6.2958e-03, -4.1805e-02,\n",
      "         2.3832e-02, -1.0176e-01, -5.2356e-02, -5.2288e-02,  8.5669e-02,\n",
      "         6.8505e-02, -6.3248e-02, -1.6879e-02, -2.7382e-02, -2.1840e-02,\n",
      "         2.3431e-02, -7.9552e-02, -1.0208e-01,  2.8098e-02, -1.1157e-01,\n",
      "        -1.7213e-02, -8.4040e-02, -1.3586e-03, -1.1422e-01, -2.0420e-02,\n",
      "        -3.9404e-03, -2.7651e-02,  1.1988e-01, -6.9561e-03, -2.9447e-02,\n",
      "        -9.9871e-02, -1.2078e-01,  3.3731e-02,  2.8366e-02,  6.9814e-02,\n",
      "        -6.6926e-02, -4.5807e-02, -4.9858e-02,  8.2351e-02,  3.9172e-02,\n",
      "        -3.9391e-02,  1.1587e-01,  1.1197e-01,  6.9504e-02, -3.5825e-02,\n",
      "        -7.0754e-02,  7.0469e-02, -1.1818e-01,  7.9868e-02,  6.6377e-03,\n",
      "        -7.3947e-03, -7.9162e-03,  1.7170e-02, -4.2426e-02]))])\n"
     ]
    }
   ],
   "source": [
    "check_model_w(MODEL_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:552: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:44: attribute 'model' removed from hparams because it cannot be pickled\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: ModelCheckpoint\n",
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /workspace/NSL_2_AUDIO/signa2text/src/artifacts/test exists and is not empty.\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | TESTAUTOENCODER | 101 K \n",
      "------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|| 16/16 [00:01<00:00, 10.84it/s, v_num=kxtp]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|| 16/16 [00:01<00:00, 10.82it/s, v_num=kxtp]\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"16-mixed\",\n",
    "    logger=wandb_logger,\n",
    "    profiler=profiler,\n",
    "    strategy=\"auto\",\n",
    "    check_val_every_n_epoch=5,\n",
    "    max_epochs=15\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=MODEL_,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader, ckpt_path = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: model.encoder.l1.0.weight, Size: torch.Size([64, 784])\n",
      "Parameter: model.encoder.l1.0.bias, Size: torch.Size([64])\n",
      "Parameter: model.encoder.l1.2.weight, Size: torch.Size([3, 64])\n",
      "Parameter: model.encoder.l1.2.bias, Size: torch.Size([3])\n",
      "Parameter: model.decoder.l1.0.weight, Size: torch.Size([64, 3])\n",
      "Parameter: model.decoder.l1.0.bias, Size: torch.Size([64])\n",
      "Parameter: model.decoder.l1.2.weight, Size: torch.Size([784, 64])\n",
      "Parameter: model.decoder.l1.2.bias, Size: torch.Size([784])\n",
      "OrderedDict([('model.encoder.l1.0.weight', tensor([[-0.0210,  0.0298, -0.0125,  ...,  0.0038,  0.0356,  0.0230],\n",
      "        [-0.0032, -0.0128, -0.0298,  ...,  0.0432,  0.0109, -0.0089],\n",
      "        [ 0.0122, -0.0500,  0.0212,  ...,  0.0224,  0.0129, -0.0353],\n",
      "        ...,\n",
      "        [-0.0350,  0.0299,  0.0092,  ..., -0.0325,  0.0414,  0.0038],\n",
      "        [-0.0198,  0.0006, -0.0258,  ..., -0.0216,  0.0161,  0.0072],\n",
      "        [ 0.0133,  0.0207, -0.0245,  ..., -0.0178,  0.0005,  0.0099]])), ('model.encoder.l1.0.bias', tensor([ 0.0062, -0.0248,  0.0121,  0.0022, -0.0090, -0.0069,  0.0119, -0.0033,\n",
      "        -0.0237, -0.0008,  0.0296,  0.0252,  0.0446, -0.0282,  0.0140, -0.0091,\n",
      "         0.0086, -0.0026,  0.0194,  0.0202,  0.0054, -0.0184, -0.0076,  0.0229,\n",
      "         0.0193, -0.0267,  0.0009, -0.0097, -0.0214,  0.0220, -0.0289,  0.0100,\n",
      "        -0.0248,  0.0201,  0.0088,  0.0207,  0.0020, -0.0105, -0.0128,  0.0160,\n",
      "        -0.0040, -0.0057,  0.0219, -0.0320, -0.0224,  0.0332, -0.0059, -0.0122,\n",
      "         0.0178, -0.0121, -0.0092,  0.0275,  0.0465,  0.0148,  0.0062,  0.0261,\n",
      "        -0.0024, -0.0160, -0.0249,  0.0302,  0.0149,  0.0489,  0.0158,  0.0236])), ('model.encoder.l1.2.weight', tensor([[ 6.9274e-02, -7.5529e-02,  6.0693e-03,  7.2484e-02,  1.2199e-02,\n",
      "          1.0271e-01, -4.1468e-02, -4.3240e-02, -4.6281e-02,  1.2571e-01,\n",
      "         -8.5449e-02,  4.6357e-02,  1.2251e-01,  2.0674e-02,  2.1539e-02,\n",
      "         -5.5167e-02, -7.4029e-02, -6.4833e-02, -1.2041e-01, -2.8743e-02,\n",
      "          1.4320e-04, -4.0567e-02,  5.1052e-02,  1.0420e-01, -6.0000e-02,\n",
      "          3.4384e-02,  1.0103e-02,  7.4126e-02,  3.0616e-02,  1.0212e-01,\n",
      "          4.6894e-02,  3.0109e-03, -3.7498e-02, -7.4668e-02, -1.0156e-01,\n",
      "         -3.9994e-02,  7.8412e-02,  2.2870e-02,  8.6772e-02, -6.5163e-02,\n",
      "         -3.6942e-02, -1.0492e-02,  5.7533e-02, -9.4895e-02,  2.8295e-02,\n",
      "          1.0956e-01,  7.9914e-02,  5.0903e-02,  1.6608e-02, -7.2153e-03,\n",
      "          1.1555e-01, -6.8021e-02, -6.0011e-02, -1.2695e-01,  1.1792e-01,\n",
      "         -3.6230e-02, -6.9247e-02,  5.4702e-02, -9.2952e-02, -2.1146e-02,\n",
      "          9.9330e-02,  8.9216e-02, -9.4121e-02,  7.8249e-02],\n",
      "        [-1.1575e-01, -5.1897e-02,  1.0679e-01, -6.7454e-02,  9.3848e-02,\n",
      "         -1.2586e-01,  7.7469e-02, -8.2629e-02,  1.4323e-02,  1.0670e-01,\n",
      "         -1.0372e-01, -6.4982e-02,  5.9872e-02,  8.2531e-02, -1.4330e-02,\n",
      "          1.2318e-01, -3.4196e-02, -3.8210e-02,  3.3245e-02,  9.5731e-02,\n",
      "          4.2358e-02, -2.4778e-02, -1.2134e-01, -3.1321e-02, -2.1474e-02,\n",
      "          7.6230e-02,  2.3832e-02, -3.9135e-02,  9.7023e-02,  1.6648e-02,\n",
      "         -6.2862e-02, -5.6612e-02,  2.3771e-02,  1.1751e-01, -1.1303e-01,\n",
      "          1.5360e-02,  5.7133e-03,  1.8234e-02,  1.1235e-01, -9.9172e-02,\n",
      "          6.8622e-02, -8.7760e-03, -4.3313e-02, -1.0790e-01,  2.2461e-02,\n",
      "          7.0563e-02,  2.9182e-02,  8.2253e-02, -1.0640e-01, -4.2185e-02,\n",
      "         -1.4459e-03,  3.8177e-03, -2.1107e-02,  1.4670e-02, -6.2533e-02,\n",
      "         -7.6777e-02, -3.9636e-02, -1.0631e-01,  1.0836e-01, -3.6008e-02,\n",
      "          3.4126e-02, -5.0305e-02,  4.2304e-02,  5.9818e-02],\n",
      "        [ 3.1594e-02,  1.3245e-01, -6.5499e-02, -1.1578e-01,  4.9889e-04,\n",
      "         -1.1455e-01,  1.1144e-01,  2.3629e-02, -6.7507e-02,  7.7308e-02,\n",
      "         -7.5380e-02, -8.7460e-02, -2.2607e-02, -2.6173e-02,  6.1487e-02,\n",
      "          1.1767e-01,  1.1865e-02,  1.1520e-01, -2.9354e-03,  8.2126e-02,\n",
      "         -2.3179e-02, -1.1608e-01, -1.8102e-02,  6.5836e-02, -2.0568e-03,\n",
      "         -9.9813e-02,  3.7159e-02, -7.9649e-02,  1.0134e-01,  8.8260e-02,\n",
      "          8.7228e-02, -1.0693e-03, -2.9712e-02, -1.6978e-02,  3.8507e-02,\n",
      "          9.1717e-02,  1.2082e-02, -1.1933e-01, -3.8271e-02,  1.1998e-02,\n",
      "         -1.2519e-02,  5.3483e-02, -9.7749e-02, -8.8274e-02, -5.6516e-02,\n",
      "         -6.7865e-02,  3.8011e-02, -5.8109e-02,  1.0606e-02,  9.7600e-02,\n",
      "         -3.9109e-02,  4.7216e-02,  7.0497e-02,  2.2784e-02,  1.0050e-01,\n",
      "          7.7916e-02, -1.1250e-02, -7.9930e-02,  2.1842e-02, -5.8862e-02,\n",
      "          6.8248e-05,  8.4067e-02, -4.1553e-02,  1.4315e-01]])), ('model.encoder.l1.2.bias', tensor([ 0.0123, -0.1229,  0.0227])), ('model.decoder.l1.0.weight', tensor([[ 0.1795,  0.5172, -0.5239],\n",
      "        [-0.4497, -0.4899, -0.4504],\n",
      "        [-0.0912,  0.0986,  0.0100],\n",
      "        [-0.4663, -0.1113, -0.5387],\n",
      "        [-0.2089, -0.4492,  0.0087],\n",
      "        [ 0.3608, -0.3248, -0.1360],\n",
      "        [ 0.5300,  0.5858, -0.3964],\n",
      "        [ 0.3922, -0.3060,  0.1450],\n",
      "        [-0.2152, -0.3432,  0.4688],\n",
      "        [-0.4522,  0.0287,  0.2911],\n",
      "        [ 0.4539, -0.5133, -0.2899],\n",
      "        [ 0.4076, -0.1734, -0.2956],\n",
      "        [ 0.4747, -0.4798,  0.0942],\n",
      "        [-0.3243,  0.0833, -0.2797],\n",
      "        [-0.4368, -0.0309, -0.1708],\n",
      "        [ 0.3086, -0.0581, -0.1212],\n",
      "        [-0.0612,  0.2382,  0.4824],\n",
      "        [ 0.3255, -0.0811,  0.0382],\n",
      "        [ 0.2721,  0.3198, -0.0203],\n",
      "        [ 0.4752,  0.3496, -0.0876],\n",
      "        [ 0.1687, -0.4548,  0.1764],\n",
      "        [-0.4151,  0.5270, -0.0039],\n",
      "        [-0.3529, -0.6163,  0.2576],\n",
      "        [-0.5152,  0.1683, -0.6333],\n",
      "        [-0.5525,  0.4203,  0.5202],\n",
      "        [-0.4121, -0.2755, -0.1049],\n",
      "        [-0.4542,  0.5371, -0.3894],\n",
      "        [ 0.0415, -0.0705,  0.3759],\n",
      "        [ 0.3816, -0.4951,  0.1492],\n",
      "        [-0.0968,  0.0525, -0.2413],\n",
      "        [-0.2245,  0.0933,  0.1174],\n",
      "        [ 0.4232, -0.1949,  0.2099],\n",
      "        [-0.3583,  0.1349,  0.3900],\n",
      "        [-0.3073,  0.5334, -0.4608],\n",
      "        [-0.1059,  0.0187,  0.4067],\n",
      "        [-0.0587, -0.1024, -0.1263],\n",
      "        [-0.1592, -0.5538,  0.4154],\n",
      "        [-0.3881,  0.1758, -0.1094],\n",
      "        [ 0.4147, -0.0134,  0.4569],\n",
      "        [ 0.4620,  0.5706,  0.2067],\n",
      "        [-0.5271,  0.5039,  0.5306],\n",
      "        [-0.5463,  0.3662,  0.0279],\n",
      "        [-0.4428, -0.4080,  0.5055],\n",
      "        [ 0.1807, -0.1169, -0.5450],\n",
      "        [-0.0655,  0.4277,  0.2231],\n",
      "        [-0.1960,  0.5915, -0.0528],\n",
      "        [ 0.4102, -0.3961, -0.2881],\n",
      "        [-0.0067, -0.0549, -0.5560],\n",
      "        [-0.3606,  0.4519,  0.5416],\n",
      "        [-0.1010,  0.6537,  0.3329],\n",
      "        [ 0.3002, -0.4298, -0.2836],\n",
      "        [ 0.0899,  0.4470, -0.5258],\n",
      "        [-0.4940,  0.3502, -0.4641],\n",
      "        [-0.3924,  0.3863,  0.0227],\n",
      "        [ 0.2113,  0.1447, -0.0590],\n",
      "        [-0.4112, -0.4971, -0.6006],\n",
      "        [ 0.2908, -0.4662, -0.2643],\n",
      "        [ 0.5162,  0.5480, -0.5867],\n",
      "        [ 0.2850, -0.2123,  0.2970],\n",
      "        [ 0.2396,  0.5301,  0.0735],\n",
      "        [ 0.3430, -0.3119,  0.3708],\n",
      "        [ 0.5119,  0.3535,  0.4323],\n",
      "        [-0.4782,  0.1609,  0.3117],\n",
      "        [-0.5876, -0.4920, -0.5328]])), ('model.decoder.l1.0.bias', tensor([ 0.3576,  0.5129, -0.5764, -0.2854,  0.3037,  0.2957, -0.0878,  0.3606,\n",
      "         0.1005, -0.3545, -0.3383,  0.1240, -0.0044,  0.2028,  0.4835,  0.3027,\n",
      "        -0.3354, -0.0807,  0.4106,  0.3863, -0.4817,  0.3527, -0.5550, -0.2983,\n",
      "        -0.4240,  0.3300,  0.4725,  0.2974, -0.3869,  0.4288,  0.5239, -0.5441,\n",
      "         0.2318,  0.4662,  0.2204, -0.4968, -0.3045, -0.4021, -0.3657, -0.5094,\n",
      "        -0.2533,  0.0050,  0.2340, -0.2808,  0.2893, -0.2298, -0.3445, -0.0172,\n",
      "         0.2394, -0.4076,  0.4034,  0.4424, -0.5034,  0.4948,  0.5059,  0.1139,\n",
      "        -0.5496, -0.0287, -0.2677,  0.2021,  0.1151, -0.2104, -0.1020,  0.0460])), ('model.decoder.l1.2.weight', tensor([[ 0.0345,  0.0705,  0.0231,  ..., -0.0489, -0.0186,  0.0839],\n",
      "        [ 0.0658,  0.1032, -0.0961,  ...,  0.0856, -0.0153, -0.1584],\n",
      "        [-0.0448,  0.0721, -0.0114,  ...,  0.0542,  0.0564,  0.0664],\n",
      "        ...,\n",
      "        [ 0.0687, -0.0599, -0.0579,  ..., -0.1276, -0.1539,  0.0807],\n",
      "        [ 0.0516, -0.0329,  0.0951,  ..., -0.1319,  0.1048, -0.0739],\n",
      "        [ 0.0864, -0.0691, -0.0700,  ..., -0.1364, -0.0731, -0.1042]])), ('model.decoder.l1.2.bias', tensor([-8.9516e-04, -1.8210e-02, -9.7208e-02,  1.0493e-01,  6.7996e-02,\n",
      "        -4.1993e-02,  2.6563e-02,  7.0861e-02,  1.0588e-01,  1.3536e-02,\n",
      "        -9.6543e-02, -1.5800e-03,  8.8386e-02,  4.9194e-02, -1.0136e-01,\n",
      "         7.1668e-02,  1.8698e-03,  6.4424e-02,  1.6498e-02,  1.0342e-02,\n",
      "        -8.8966e-02, -6.6123e-02,  2.5884e-02, -3.6901e-03, -8.9153e-02,\n",
      "         5.5217e-02,  8.3813e-02, -9.8135e-03,  7.3290e-02,  7.1811e-03,\n",
      "         9.8489e-02,  6.0257e-02, -5.1043e-02,  8.2064e-02,  9.7692e-02,\n",
      "        -1.1645e-01, -8.0466e-02,  1.3150e-02,  2.1219e-02, -3.2333e-02,\n",
      "        -8.6310e-02, -1.4841e-02,  1.1838e-01, -9.9596e-02, -1.1009e-01,\n",
      "         7.4138e-02, -5.2891e-02, -1.2539e-01, -6.2458e-02,  8.5837e-02,\n",
      "         8.0039e-02,  3.3411e-03, -5.8376e-02,  3.7585e-02,  8.3278e-02,\n",
      "         8.7285e-02, -1.0750e-01,  1.0493e-01,  8.9126e-02,  9.2420e-03,\n",
      "        -2.8376e-02, -7.8213e-02, -3.7888e-03, -1.1794e-01,  1.7975e-02,\n",
      "        -9.0442e-02,  5.6256e-02,  8.1867e-02,  1.2853e-01, -6.2478e-03,\n",
      "         6.2288e-02,  7.0001e-02,  7.8153e-02, -7.3412e-02,  7.9412e-02,\n",
      "         4.3042e-02, -1.7613e-02,  4.6726e-02, -7.8159e-02, -4.2322e-02,\n",
      "         6.1589e-02, -3.9467e-02,  5.0509e-02,  5.4545e-03, -2.0185e-03,\n",
      "         6.1215e-02,  1.2799e-01, -6.4896e-02, -9.1956e-02,  8.0772e-02,\n",
      "        -2.0791e-02, -4.6864e-02, -1.2774e-01, -2.1929e-02, -8.0961e-02,\n",
      "         1.1433e-02, -9.9571e-02, -2.2906e-02, -8.6125e-03,  3.1133e-02,\n",
      "         7.3842e-02, -1.6428e-02,  2.7327e-02, -6.9793e-02, -4.6415e-02,\n",
      "         3.9832e-02, -1.9776e-02,  8.4722e-02,  1.0166e-01, -4.6371e-02,\n",
      "         9.0767e-02, -3.1342e-02, -5.7270e-02,  8.3754e-02, -1.8999e-02,\n",
      "        -1.1871e-01,  5.4263e-02,  2.2304e-02, -3.3161e-02, -8.0872e-02,\n",
      "         1.1534e-01, -5.1667e-02, -5.9610e-02,  1.6003e-02,  4.1252e-02,\n",
      "         2.7384e-02,  4.2023e-02, -1.3528e-03, -6.7230e-02,  4.8869e-02,\n",
      "         1.7510e-02,  3.0712e-03,  2.8720e-03,  6.0459e-02,  2.1394e-02,\n",
      "        -3.0413e-02, -4.9825e-02, -7.0050e-02, -1.3266e-02, -2.4805e-02,\n",
      "        -9.0569e-02,  6.1598e-03,  2.4786e-02, -6.3157e-02,  8.0125e-02,\n",
      "        -3.3334e-02, -1.9743e-03, -3.0661e-02,  9.0990e-03, -4.3907e-02,\n",
      "        -1.0388e-01, -5.0734e-02,  9.6381e-02, -1.2387e-02,  7.2319e-02,\n",
      "        -3.2346e-02, -4.7110e-02,  7.2307e-04,  1.4788e-02, -8.8091e-03,\n",
      "        -9.7576e-02,  6.2801e-02,  4.6759e-02, -4.5681e-02, -5.8191e-02,\n",
      "         2.6445e-02, -8.0185e-02,  6.4004e-02,  7.5497e-03, -1.3808e-02,\n",
      "         7.9674e-02, -3.5269e-02,  3.6039e-03, -8.0034e-02, -9.6587e-03,\n",
      "        -1.1896e-02, -7.0626e-02, -6.7350e-02,  4.5870e-02,  9.7277e-02,\n",
      "        -7.7387e-02,  9.0504e-02,  1.2328e-01,  3.5192e-02,  3.6317e-02,\n",
      "        -6.6572e-02,  1.1960e-02, -5.9801e-02,  1.0004e-01,  1.0630e-02,\n",
      "        -5.7973e-03, -7.2879e-02, -7.9821e-02, -4.1332e-03,  7.9385e-02,\n",
      "        -1.0852e-01,  1.9802e-05,  4.4632e-02,  3.5893e-02,  9.3177e-02,\n",
      "         2.0049e-02, -1.0266e-01, -5.9588e-02, -1.0787e-01,  1.0194e-01,\n",
      "         8.5164e-02,  3.5522e-02,  1.0029e-01, -9.9412e-02, -5.9816e-02,\n",
      "        -3.3976e-02, -9.3578e-05, -1.4204e-02, -2.1501e-03,  1.1323e-01,\n",
      "         4.7845e-02,  1.5198e-02,  4.4977e-02,  5.7214e-02,  1.2509e-02,\n",
      "         7.6535e-02,  9.5581e-02, -2.7016e-02,  8.4082e-02, -5.6882e-03,\n",
      "        -1.8421e-02, -7.5922e-02,  2.9650e-02, -3.0997e-02, -5.3814e-02,\n",
      "        -3.9865e-02, -7.6636e-02,  8.0502e-02, -2.3340e-02,  2.7275e-02,\n",
      "        -7.4813e-02, -1.9788e-02, -1.3295e-02,  3.7737e-02,  1.0103e-01,\n",
      "         7.2123e-02, -3.4246e-02, -1.2521e-02, -5.9071e-02, -5.7925e-02,\n",
      "        -8.1510e-02, -6.0237e-02,  5.4310e-02, -5.9171e-02,  4.1139e-02,\n",
      "        -6.5763e-03, -6.3726e-03, -5.3459e-02,  1.3260e-02, -8.2359e-02,\n",
      "        -8.9379e-02,  4.0438e-03,  4.1909e-02, -1.0203e-01,  7.5866e-02,\n",
      "         4.9855e-03,  9.7653e-02,  1.1558e-01, -8.9685e-02,  5.8326e-02,\n",
      "        -4.4696e-02, -7.2392e-02,  5.2693e-02, -1.1481e-02,  5.6105e-02,\n",
      "         6.3092e-02, -6.5210e-02, -6.8472e-02,  1.4367e-02, -2.1634e-02,\n",
      "         9.6318e-02, -1.0503e-01, -1.9735e-02, -1.9705e-02, -1.0038e-01,\n",
      "         8.7589e-02,  4.9962e-02,  1.0955e-01, -1.2764e-02,  4.8215e-02,\n",
      "        -9.5351e-02, -8.9001e-03,  3.9338e-02, -3.0442e-02, -9.1985e-02,\n",
      "        -8.2658e-02, -3.0804e-02,  7.2849e-02,  8.8848e-02, -1.0861e-01,\n",
      "         9.9118e-02, -8.4176e-02, -6.0203e-02,  7.1453e-02, -9.3654e-02,\n",
      "        -6.5426e-02, -5.0832e-02,  7.6855e-02,  1.4967e-02,  1.0205e-02,\n",
      "         2.4192e-02, -1.0108e-01,  1.0326e-01,  2.1445e-02,  3.0911e-02,\n",
      "        -5.9110e-02,  9.9869e-02, -3.6737e-02, -2.7616e-02, -7.2242e-02,\n",
      "        -5.1195e-02, -2.4359e-02, -1.0113e-01,  3.9659e-02,  5.0161e-02,\n",
      "        -7.3891e-02,  6.1251e-02,  5.1583e-02, -9.4034e-02,  8.2186e-02,\n",
      "        -9.8046e-02, -5.2434e-02, -4.1787e-02,  1.3322e-01,  8.6180e-02,\n",
      "        -8.1825e-02, -1.1015e-01,  3.5361e-02, -6.0027e-02, -1.1607e-01,\n",
      "        -4.6418e-02, -8.8029e-02, -2.9790e-02,  3.1320e-02,  2.4836e-02,\n",
      "        -8.9318e-02, -1.0663e-01, -4.5699e-02,  1.1811e-01, -5.2726e-02,\n",
      "         1.5802e-02,  5.4119e-02,  5.6837e-02, -2.7920e-02,  1.0743e-01,\n",
      "         5.9118e-02, -3.4690e-04,  9.7001e-02, -8.1232e-02,  3.2855e-02,\n",
      "        -6.2416e-02, -4.8703e-02,  7.4853e-02,  1.4499e-03, -8.9817e-02,\n",
      "         9.0855e-02,  7.1091e-02,  3.5331e-02,  4.9267e-02,  3.1102e-02,\n",
      "        -1.0794e-01,  6.3137e-02,  1.0096e-01,  2.3475e-02, -1.1427e-01,\n",
      "        -1.1430e-01, -4.5485e-02,  1.2278e-01,  1.0404e-02, -6.7295e-02,\n",
      "         1.0579e-01, -7.7344e-03,  4.1723e-02,  8.9785e-03,  2.0576e-03,\n",
      "         8.4878e-02, -1.0831e-01, -4.4587e-02, -7.6135e-02, -1.1398e-01,\n",
      "        -1.2148e-02, -3.6396e-02, -1.0217e-01,  4.5424e-02,  1.0677e-01,\n",
      "        -7.2609e-02, -8.0460e-02, -1.0786e-01, -5.2982e-02,  5.1861e-02,\n",
      "        -8.4988e-02, -5.3540e-02,  8.7445e-02,  7.8316e-02, -1.1831e-01,\n",
      "         3.3384e-02, -6.5269e-02, -4.0040e-02,  4.9846e-02,  2.9253e-02,\n",
      "        -9.8940e-02,  3.6471e-02,  3.6255e-02,  3.9350e-02,  3.8245e-02,\n",
      "        -7.9248e-02,  3.0593e-02, -6.7983e-02,  8.6086e-02, -7.3263e-02,\n",
      "         3.5924e-02,  9.1532e-02, -3.3955e-03,  8.9160e-02, -8.9279e-02,\n",
      "        -4.7485e-02,  6.6893e-02,  5.3482e-02,  3.5888e-02, -8.2268e-02,\n",
      "        -1.0606e-01, -1.4960e-02, -8.0840e-02,  2.5149e-02, -6.6385e-03,\n",
      "        -5.2396e-02,  8.0260e-02, -5.4088e-02, -8.5959e-02, -2.3423e-02,\n",
      "        -5.0812e-02,  9.1448e-02, -2.3830e-02, -4.8422e-02,  4.8045e-02,\n",
      "        -2.3107e-02,  4.1529e-03, -8.6021e-02,  7.9398e-02, -2.6583e-02,\n",
      "        -8.1404e-02,  1.2257e-02, -5.8049e-02,  1.2074e-02,  6.4849e-02,\n",
      "        -6.3521e-02, -1.7007e-02, -6.5823e-02,  6.6733e-02, -9.1921e-02,\n",
      "         4.3477e-02, -2.1424e-02, -4.8618e-02,  8.8082e-02, -3.2190e-02,\n",
      "         1.9402e-02, -1.0677e-01,  8.7343e-02, -2.5104e-03, -3.2857e-06,\n",
      "        -1.6322e-02,  4.7297e-02,  6.6649e-02, -9.2476e-02,  6.8612e-02,\n",
      "         4.5439e-02, -9.9872e-02,  2.5617e-02,  1.1118e-03, -6.7482e-02,\n",
      "        -1.8166e-02, -5.1351e-02, -6.1322e-02,  6.4307e-02, -3.8520e-02,\n",
      "        -1.0049e-01, -6.3446e-02, -8.2208e-02, -9.3797e-02,  4.9575e-02,\n",
      "        -7.9386e-02, -7.1911e-03,  6.5638e-02, -5.4052e-02, -6.6955e-02,\n",
      "        -2.3382e-02,  8.4918e-02, -5.0029e-03, -1.3113e-02,  1.4571e-02,\n",
      "        -5.8461e-02, -2.6606e-02,  4.3783e-02,  4.5387e-02,  1.1000e-01,\n",
      "        -1.0555e-01,  7.5485e-02,  3.1744e-02,  9.4369e-02, -8.7006e-03,\n",
      "        -6.5317e-03, -4.2457e-02,  3.5739e-02, -5.4433e-03,  1.0384e-01,\n",
      "         1.4465e-01, -6.7657e-02, -9.2673e-02, -6.5842e-02, -5.8419e-02,\n",
      "        -7.1155e-02, -8.7039e-03, -1.2318e-01, -7.0431e-03, -9.0724e-02,\n",
      "         8.1796e-02,  7.7540e-03,  6.5527e-02,  3.7105e-02, -7.6668e-02,\n",
      "        -2.6321e-02,  2.4379e-02, -7.4322e-02,  9.0643e-02, -4.0101e-03,\n",
      "         3.5244e-02, -1.2670e-01, -1.1029e-02,  5.2199e-02,  7.5166e-03,\n",
      "        -6.3233e-03,  1.0887e-01,  4.9073e-02, -8.5610e-02,  2.6325e-02,\n",
      "        -2.1244e-02, -9.3881e-03,  2.7816e-02, -2.4199e-02,  1.0992e-01,\n",
      "        -7.3171e-02, -5.3486e-02,  4.6416e-02, -8.5735e-02, -7.1510e-02,\n",
      "        -6.0993e-02,  1.1012e-01, -4.9729e-02, -5.5333e-02, -9.2836e-02,\n",
      "         4.0677e-02, -6.0987e-02,  7.6850e-02, -1.0687e-01, -2.2079e-02,\n",
      "         2.2404e-02,  1.7850e-02,  5.2493e-02, -2.1718e-02, -1.4431e-02,\n",
      "        -5.3525e-02, -8.5234e-02, -6.8258e-02,  6.1886e-02, -9.1732e-02,\n",
      "        -6.8911e-02, -5.4877e-02,  2.5246e-03,  1.5244e-03,  4.4222e-02,\n",
      "        -7.7282e-02, -3.1680e-02,  5.7115e-02,  8.1075e-03, -6.8916e-02,\n",
      "        -7.6559e-03,  9.3933e-03,  1.2054e-02,  6.6220e-02, -5.1010e-02,\n",
      "         8.2999e-02,  8.4270e-02,  4.0016e-04,  1.0271e-02, -8.9348e-03,\n",
      "         6.2423e-02,  2.9377e-02, -7.1913e-02,  8.8298e-02, -9.5689e-02,\n",
      "         3.0253e-02,  1.2748e-02,  2.3298e-02, -4.3870e-02,  2.8552e-02,\n",
      "        -9.4100e-02,  8.2423e-02,  1.0427e-01, -1.7501e-02, -1.0186e-01,\n",
      "        -1.1488e-01, -1.8113e-02, -5.5225e-02, -5.8315e-02, -1.0280e-01,\n",
      "        -3.9101e-03, -2.0046e-02, -6.4466e-02, -9.6451e-03,  9.0761e-02,\n",
      "         1.1615e-02, -2.8483e-02, -4.5406e-02,  4.2986e-02,  3.8508e-03,\n",
      "         2.3267e-02, -9.9518e-02, -7.8684e-02,  1.0064e-01,  7.3067e-02,\n",
      "         1.3346e-01,  4.6635e-02, -4.7516e-02,  3.0155e-02, -5.9483e-03,\n",
      "         6.1577e-02,  4.7249e-02,  3.3760e-02,  6.8614e-02, -1.4885e-02,\n",
      "        -6.2946e-02, -6.0960e-02, -4.4117e-02, -4.1399e-02, -1.1848e-01,\n",
      "        -6.6951e-02,  4.6017e-02,  3.6729e-03, -1.0725e-01, -8.3685e-02,\n",
      "         3.7253e-02,  1.1445e-01, -1.6177e-02,  2.3695e-02,  1.0049e-01,\n",
      "         3.8161e-02, -7.7318e-02, -5.4008e-02, -1.2761e-02, -1.2764e-02,\n",
      "         6.5794e-02,  9.1020e-02,  9.6420e-02,  4.9940e-02, -9.8095e-02,\n",
      "         8.2758e-02,  9.4268e-02,  6.6576e-02,  3.8331e-02,  6.2736e-02,\n",
      "         1.1078e-01, -5.9769e-02, -5.7441e-02, -5.7217e-02, -1.5986e-02,\n",
      "         3.1228e-02, -1.9609e-02, -2.0240e-02,  5.1307e-02,  1.2325e-01,\n",
      "        -6.1745e-02, -6.2254e-02, -3.4338e-02,  9.0756e-02, -5.1858e-02,\n",
      "         1.2622e-01, -7.6079e-02, -3.5264e-02,  1.0277e-01,  2.3924e-02,\n",
      "        -9.7069e-02, -4.9454e-02, -6.9637e-04,  6.9388e-02,  1.0413e-01,\n",
      "        -7.3938e-03,  4.5084e-02,  1.3532e-01,  3.0131e-02, -3.2576e-03,\n",
      "         7.5903e-02, -9.3906e-02, -5.3140e-02,  4.0723e-02,  4.1423e-02,\n",
      "         9.0686e-02,  6.8372e-02,  1.3464e-01, -9.1501e-02, -4.8266e-02,\n",
      "        -7.0657e-02,  2.3607e-02,  8.0476e-02,  5.8574e-02, -9.3793e-02,\n",
      "         5.0338e-02, -9.6929e-03, -3.3096e-02,  2.2787e-02,  1.4759e-02,\n",
      "         1.4796e-02,  6.5653e-02, -7.5869e-02, -8.0484e-02, -8.2850e-02,\n",
      "         3.2352e-03,  1.7724e-02, -7.9537e-02,  1.0465e-01, -9.8474e-02,\n",
      "        -8.8483e-02,  2.9263e-02, -2.6299e-02,  1.2068e-01, -5.6644e-02,\n",
      "        -7.3026e-02,  1.3149e-01, -7.6489e-02, -2.5422e-02, -4.8026e-02,\n",
      "         2.6889e-02, -9.8976e-02, -5.0784e-02, -4.7562e-02,  8.3888e-02,\n",
      "         6.7930e-02, -6.5345e-02, -2.3397e-02, -2.1531e-02, -1.1532e-02,\n",
      "         2.3375e-02, -7.0807e-02, -8.6473e-02,  1.7951e-02, -1.0602e-01,\n",
      "        -3.6343e-02, -8.2065e-02,  6.4148e-03, -9.3989e-02, -2.3969e-04,\n",
      "         1.4089e-02, -1.1225e-02,  1.3749e-01, -3.4601e-02, -4.1253e-02,\n",
      "        -1.1495e-01, -1.3460e-01,  1.8964e-02,  4.1703e-02,  6.5068e-02,\n",
      "        -4.9527e-02, -4.6610e-02, -3.5785e-02,  6.7825e-02,  2.4006e-02,\n",
      "        -3.2438e-02,  1.0445e-01,  9.2612e-02,  7.2684e-02, -2.9991e-02,\n",
      "        -6.3186e-02,  6.7917e-02, -9.4241e-02,  1.0861e-01,  2.4773e-02,\n",
      "        -8.4209e-03, -5.2269e-03,  2.6935e-02, -2.1932e-02]))])\n"
     ]
    }
   ],
   "source": [
    "check_model_w(MODEL_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
